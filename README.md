# ğŸ  Agregador de ImÃ³veis (Web Scraper)

Este projeto Ã© uma ferramenta de automaÃ§Ã£o desenvolvida em Python para monitorizar e unificar pesquisas de imÃ³veis de diferentes sites de imobiliÃ¡rias.

O objetivo Ã© simplificar a procura de casa, centralizando os resultados de vÃ¡rias fontes (que possuem estruturas HTML diferentes) numa Ãºnica tabela padronizada. O projeto oferece agora uma **interface web** amigÃ¡vel e suporte a sites dinÃ¢micos.

## ğŸš€ Funcionalidades

-   **Multi-site:** Extrai dados de diferentes imobiliÃ¡rias (ex: KeyOn, QualAlugar).
-   **Interface Web:** Painel visual construÃ­do com Streamlit para iniciar pesquisas e visualizar resultados.
-   **Suporte a JavaScript:** Utiliza **Selenium** para carregar sites que dependem de renderizaÃ§Ã£o dinÃ¢mica.
-   **PadronizaÃ§Ã£o:** Converte dados heterogÃ©neos num formato Ãºnico (TÃ­tulo, PreÃ§o, Link, Ãrea, Quartos, etc.).
-   **ExportaÃ§Ã£o:** Gera dados prontos para anÃ¡lise (Pandas DataFrame) e permite exportaÃ§Ã£o para CSV/Excel.

## ğŸ› ï¸ Arquitetura e Tecnologias

O projeto segue os princÃ­pios de **Clean Code** e **SOLID**, garantindo escalabilidade e facilidade de manutenÃ§Ã£o:

-   **Linguagem:** Python 3.x
-   **Interface GrÃ¡fica:** `streamlit`
-   **Web Scraping:** `selenium` (navegaÃ§Ã£o), `beautifulsoup4` (parsing HTML)
-   **AnÃ¡lise de Dados:** `pandas`
-   **PadrÃµes de Projeto:**
    -   **Factory Method:** Para a criaÃ§Ã£o dos scrapers adequados (`ScraperFactory`).
    -   **Repository Pattern:** Para abstrair a persistÃªncia/armazenamento dos dados (`ImovelRepository`).
    -   **Strategy Pattern:** Cada imobiliÃ¡ria possui a sua estratÃ©gia de extraÃ§Ã£o.
    -   **Separation of Concerns:** DivisÃ£o clara entre *Scraping* (baixar dados) e *Parsing* (interpretar dados).

### Estrutura de Pastas

```text
imobiliarias/
â”œâ”€â”€ app.py                  # Interface Web (Streamlit)
â”œâ”€â”€ main.py                 # Orquestrador (Terminal/CLI)
â”œâ”€â”€ config/                 # ConfiguraÃ§Ãµes (URLs, variÃ¡veis)
â”œâ”€â”€ domain/                 # Modelos de dados (Imovel, ScraperResult)
â”œâ”€â”€ factories/              # CriaÃ§Ã£o de instÃ¢ncias dos scrapers
â”œâ”€â”€ infrastructure/         # Clientes HTTP/Selenium
â”œâ”€â”€ interfaces/             # Contratos (Protocolos/ABCs)
â”œâ”€â”€ parsers/                # LÃ³gica de extraÃ§Ã£o de dados do HTML
â”œâ”€â”€ repositories/           # GestÃ£o e armazenamento dos dados extraÃ­dos
â”œâ”€â”€ scrapers/               # OrquestraÃ§Ã£o do fluxo de busca por site
â””â”€â”€ services/               # LÃ³gica de negÃ³cio (Logs, Manager)

```

## ğŸ“¦ Como Instalar

1. **Clone o repositÃ³rio** ou descarregue os ficheiros.
2. **Crie um ambiente virtual** (recomendado):
```bash
python -m venv venv
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

```


3. **Instale as dependÃªncias:**
```bash
pip install pandas beautifulsoup4 selenium webdriver-manager streamlit openpyxl

```


*(Nota: Ã‰ necessÃ¡rio ter o Google Chrome instalado na mÃ¡quina para o Selenium funcionar corretamente).*

## â–¶ï¸ Como Usar

Existem duas formas de utilizar a ferramenta:

### 1. Interface Web (Recomendado)

Para uma experiÃªncia visual mais agradÃ¡vel:

```bash
streamlit run imobiliarias/app.py

```

O navegador abrirÃ¡ automaticamente com o painel "Monitor de ImÃ³veis". Clique em **"ğŸš€ Executar MonitorizaÃ§Ã£o"** para iniciar.

### 2. Terminal (CLI)

Para execuÃ§Ã£o direta ou agendamento de tarefas:

```bash
python imobiliarias/main.py

```

Os resultados serÃ£o exibidos no terminal e guardados (se configurado).

## âš™ï¸ ConfiguraÃ§Ã£o

As URLs de pesquisa e ativaÃ§Ã£o de cada imobiliÃ¡ria sÃ£o geridas no ficheiro `config/settings.py`:

```python
SCRAPERS = {
    'keyon': ScraperConfig(
        name='KeyOn',
        url="...", # Insira a sua URL de pesquisa aqui
        enabled=True
    ),
    # ...
}

```

## â• Como Adicionar Nova ImobiliÃ¡ria

GraÃ§as Ã  arquitetura modular, para adicionar um novo site:

1. **Parser:** Crie um ficheiro em `parsers/` (ex: `nova_imob_parser.py`) implementando `IParser`. Use o `BeautifulSoup` aqui para extrair os dados.
2. **Scraper:** Crie um ficheiro em `scrapers/` (ex: `nova_imob.py`) implementando `IScraper`. Este usa o Parser criado acima.
3. **Factory:** Atualize o `factories/scraper_factory.py` para saber criar o novo scraper.
4. **Config:** Adicione a entrada no dicionÃ¡rio em `config/settings.py`.
5. **Registo:** No `main.py`, adicione a lÃ³gica para carregar esta nova configuraÃ§Ã£o no `configurar_scrapers`.