# ğŸ  Agregador de ImÃ³veis (Web Scraper com Pipelines)

Este projeto Ã© uma ferramenta de automaÃ§Ã£o e monitorizaÃ§Ã£o de imÃ³veis desenvolvida em Python. O sistema centraliza resultados de mÃºltiplas fontes (imobiliÃ¡rias) numa interface Ãºnica, normalizando dados e permitindo exportaÃ§Ã£o para anÃ¡lise.

A arquitetura foi modernizada para utilizar **Pipelines de Processamento**, facilitando a escalabilidade e a adiÃ§Ã£o de novos sites.

## ğŸš€ Funcionalidades

-   **Multi-site:** Suporte a mÃºltiplas imobiliÃ¡rias (atualmente configurado para *KeyOn* e *QualAlugar*).
-   **Arquitetura HÃ­brida:**
    -   *HTML Parsing:* ExtraÃ§Ã£o via seletores CSS (ex: KeyOn).
    -   *JSON Extraction:* ExtraÃ§Ã£o de dados ocultos em tags `<script>` (ex: QualAlugar).
-   **Sistema de Caching Inteligente:** Evita pedidos repetidos Ã  rede guardando o HTML localmente (hash MD5 da URL), ideal para desenvolvimento e testes.
-   **Interface Web:** Painel construÃ­do com **Streamlit** para visualizaÃ§Ã£o rÃ¡pida e links diretos.
-   **Suporte a JavaScript:** Utiliza **Selenium** (headless) para carregar sites dinÃ¢micos.
-   **ExportaÃ§Ã£o:** Gera relatÃ³rios em CSV e Excel.

## ğŸ› ï¸ Arquitetura e Tecnologias

O projeto segue princÃ­pios de **Clean Architecture** e **Design Patterns**:

-   **Linguagem:** Python 3.x
-   **Bibliotecas Principais:** `pandas`, `beautifulsoup4`, `selenium`, `streamlit`.
-   **PadrÃµes de Projeto Implementados:**
    -   **Pipeline Pattern:** O fluxo de extraÃ§Ã£o Ã© dividido em passos (`FetchStep`, `ParseStep`, `LogStep`), geridos por um `ScraperManager`.
    -   **Factory Method:** A `ScraperFactory` cria instÃ¢ncias e regista novas estratÃ©gias de extraÃ§Ã£o dinamicamente.
    -   **Adapter Pattern:** O `PipelineScraperAdapter` permite que qualquer configuraÃ§Ã£o de pipeline seja tratada como um Scraper padrÃ£o.
    -   **Repository Pattern:** AbstraÃ§Ã£o da persistÃªncia dos dados (`ImovelRepository`).

### Estrutura de Pastas

```text
imobiliarias/
â”œâ”€â”€ app.py                      # Interface Web (Streamlit)
â”œâ”€â”€ main.py                     # Entry point (CLI / Orquestrador)
â”œâ”€â”€ cache_data/                 # Armazenamento de HTMLs em cache
â”œâ”€â”€ config/                     # ConfiguraÃ§Ãµes (URLs, Features flags)
â”œâ”€â”€ domain/                     # Modelos (Imovel, ScraperResult)
â”œâ”€â”€ factories/                  # CriaÃ§Ã£o e registo de Scrapers
â”œâ”€â”€ infrastructure/             # Clientes HTTP/Selenium
â”œâ”€â”€ interfaces/                 # Contratos (Protocolos/ABCs)
â”œâ”€â”€ parsers/                    # LÃ³gica de extraÃ§Ã£o (BeautifulSoup)
â”œâ”€â”€ pipeline_steps/             # Passos reutilizÃ¡veis (Caching, Fetch, Parse)
â”œâ”€â”€ repositories/               # GestÃ£o de dados em memÃ³ria/exportaÃ§Ã£o
â”œâ”€â”€ scrapers/                   # Adaptadores e lÃ³gica especÃ­fica
â””â”€â”€ services/                   # Casos de uso e Logger

```

## ğŸ“¦ InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**
```bash
git clone <url-do-repositorio>
cd imobiliarias

```


2. **Crie o ambiente virtual:**
```bash
python -m venv venv
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

```


3. **Instale as dependÃªncias:**
```bash
pip install pandas beautifulsoup4 selenium webdriver-manager streamlit openpyxl

```


*(Nota: O Selenium farÃ¡ a gestÃ£o automÃ¡tica do driver do Chrome).*

## â–¶ï¸ Como Usar

### 1. Interface Web (Recomendado)

Para uma experiÃªncia visual e interativa:

```bash
streamlit run imobiliarias/app.py

```

Clique em **"ğŸš€ Executar MonitorizaÃ§Ã£o"** para iniciar a recolha de dados.

### 2. Terminal (CLI)

Para execuÃ§Ã£o direta ou agendamento (cron jobs):

```bash
python imobiliarias/main.py

```

## âš™ï¸ ConfiguraÃ§Ã£o

As URLs de pesquisa e a ativaÃ§Ã£o de cada imobiliÃ¡ria sÃ£o geridas em `config/settings.py`.

```python
SCRAPERS = {
    'keyon': ScraperConfig(
        name='KeyOn',
        url="...", 
        enabled=True
    ),
    # ...
}

```

## â• Como Adicionar Nova ImobiliÃ¡ria

GraÃ§as Ã  `ScraperFactory` e ao padrÃ£o Pipeline, adicionar um novo site Ã© simples:

1. **Criar Parser:** Crie um ficheiro em `parsers/` (ex: `nova_imob_parser.py`) implementando `IParser`.
2. **Registar na Factory:** No ficheiro `main.py` (funÃ§Ã£o `configurar_scrapers`), registe a nova imobiliÃ¡ria:

```python
# Exemplo em main.py
from parsers.nova_imob_parser import NovaImobParser

ScraperFactory.register(
    key='novaimob', 
    parser_cls=NovaImobParser, 
    wait_selector="div.classe-do-cartao", 
    source_name="Nova ImobiliÃ¡ria"
)

```

3. **Adicionar ConfiguraÃ§Ã£o:** Adicione a URL e a chave correspondente em `config/settings.py`.

O sistema encarregar-se-Ã¡ de criar a Pipeline, gerir o cache e o Selenium automaticamente.
